# ðŸš€ FazAI - Guia RÃ¡pido de InÃ­cio

## âš¡ ConfiguraÃ§Ã£o em 3 Passos

### 1ï¸âƒ£ Instale o FazAI rapidamente

```bash
curl -fsSL https://github.com/RLuf/FazAI/raw/master/scripts/install.sh | bash
start-codex
```

### 2ï¸âƒ£ Configure sua API Key da OpenAI

```bash
# Copie o arquivo de exemplo
cp fazai.conf.example fazai.conf

# Edite e cole sua chave OpenAI
nano fazai.conf
```

Cole sua chave OpenAI no arquivo:
```
OPENAI_API_KEY=sk-sua-chave-aqui
```

### 3ï¸âƒ£ Build manual (opcional)

```bash
npm install
npm run build
```

### 4ï¸âƒ£ Teste!

```bash
# Modo ask (seguro, nÃ£o executa nada)
node dist/app.cjs ask "O que Ã© nginx?" gpt4mini

# Modo admin com GPT-4o-mini
node dist/app.cjs --dry-run gpt4mini
```

---

## ðŸ“– Exemplos de Uso

### Modo Ask (Perguntas)

```bash
# Com GPT-4o-mini (rÃ¡pido e barato)
node dist/app.cjs ask "Como configurar nginx?" gpt4mini

# Com GPT-4o (mais inteligente)
node dist/app.cjs ask "Explicar diferenÃ§a entre systemctl e service" gpt4o
```

### Modo Admin (Comandos Linux)

```bash
# Dry-run (simula, nÃ£o executa)
node dist/app.cjs --dry-run gpt4mini

# Admin real (CUIDADO! Executa comandos)
node dist/app.cjs gpt4o
```

### Ver ConfiguraÃ§Ã£o

```bash
# Listar API keys configuradas
node dist/app.cjs config

# Abrir o CLI interativo com chat e memÃ³ria persistente
node dist/app.cjs --cli
```

---

## ðŸ” Pesquisa Automatizada (Opcional)

Quer que o FazAI busque documentaÃ§Ã£o automaticamente?

1. Configure um endpoint MCP Context7 **ou** um comando local no `fazai.conf`:

```ini
# Endpoint HTTP
MCP_CONTEXT7_URL=http://localhost:7700/context7/search

# OU comando CLI (usa {query})
MCP_CONTEXT7_COMMAND=context7 --json --query "{query}"
```

2. (Opcional) Defina o fallback web:

```ini
WEB_SEARCH_PROVIDER=duckduckgo
```

3. Para desabilitar pesquisas automÃ¡ticas (ex.: ambiente offline):

```ini
FAZAI_DISABLE_RESEARCH=true
```

> Dica: use `FAZAI_CONFIG_PATH=/caminho/fazai.conf` se quiser centralizar a configuraÃ§Ã£o em outro local.

---

## ðŸŽ¯ Modelos DisponÃ­veis

| Nickname | Modelo | Custo | Uso |
|----------|--------|-------|-----|
| `gpt4o` | GPT-4o | MÃ©dio | Tarefas complexas |
| `gpt4mini` | GPT-4o-mini | **Baixo** | Recomendado para comeÃ§ar |
| `gpt4turbo` | GPT-4 Turbo | Alto | MÃ¡xima capacidade |

---

## ðŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada (Ollama Local)

Se vocÃª tem Ollama rodando local ou em outro servidor:

```bash
# 1. Adicione ao fazai.conf
echo "OLLAMA_BASE_URL=http://localhost:11434" >> fazai.conf

# 2. Use modelos Ollama
node dist/app.cjs llama32    # Llama 3.2
node dist/app.cjs qwen        # Qwen 2.5
node dist/app.cjs mistral     # Mistral
```

---

## âš ï¸ Avisos Importantes

1. **Modo Ask**: Completamente seguro, sÃ³ responde perguntas
2. **Modo --dry-run**: Simula comandos, nÃ£o executa nada
3. **Modo Admin Normal**: **EXECUTA comandos de verdade!**
   - Comece com tarefas seguras
   - Sempre revise os comandos antes de confirmar

---

## ðŸ†˜ Problemas Comuns

### "API key nÃ£o encontrada"
```bash
# Verifique se o arquivo existe e tem a chave
cat fazai.conf
```

### "Build failed"
```bash
# Reinstale dependÃªncias
rm -rf node_modules package-lock.json
npm install
npm run build
```

### "Ollama nÃ£o conecta"
```bash
# Verifique se o Ollama estÃ¡ rodando
curl http://localhost:11434/api/tags

# Se estiver em outro servidor, configure a URL no fazai.conf
echo "OLLAMA_BASE_URL=http://IP:11434" >> fazai.conf
```

---

## ðŸ“š PrÃ³ximos Passos

1. Teste com `--dry-run` primeiro
2. Experimente diferentes modelos (gpt4mini Ã© barato!)
3. Use modo ask para perguntas sobre Linux
4. Configure Ollama para uso local gratuito

---

**DÃºvidas?** Veja o [README.md](README.md) completo ou abra uma issue!
