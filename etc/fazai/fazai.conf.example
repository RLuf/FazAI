###############################################################################
# FazAI - Arquivo de Configuração Principal
# 
# Este arquivo configura o comportamento do sistema FazAI, incluindo:
# - Provedores de IA (OpenRouter, Requesty, OpenAI)
# - Sistema de orquestração (modos de planejamento e ação)
# - Configurações gerais do sistema
#
# Localização recomendada: /etc/fazai/fazai.conf
###############################################################################

###############################################################################
# CONFIGURAÇÃO DE PROVEDORES DE IA
###############################################################################

[ai_provider]
# Define qual provedor de IA será utilizado como padrão
# Valores possíveis: openrouter, requesty, openai, ollama
# - openrouter: Utiliza a API do OpenRouter para acessar múltiplos modelos
# - requesty: Utiliza a API do Requesty para acessar múltiplos modelos
# - openai: Utiliza diretamente a API da OpenAI
# - ollama: Utiliza modelos locais via Ollama
provider = openrouter

# Configurações do Ollama (novo)
[ollama]
enabled = true
endpoint = http://localhost:11434
models = ["mixtral", "llama2", "codellama"]
cache_dir = /var/cache/fazai/ollama

# Habilita fallback automático para outro provedor em caso de falha
# Se true, tentará o próximo provedor na ordem: openrouter -> requesty -> openai
enable_fallback = false

# Número máximo de tentativas antes de desistir
max_retries = 1

# Tempo de espera entre tentativas (em segundos)
retry_delay = 1

###############################################################################
# CONFIGURAÇÃO DO OPENROUTER
###############################################################################

[openrouter]
# Chave de API do OpenRouter
# Obtenha em: https://openrouter.ai/keys
# Atualizado para a chave fornecida pelo usuário em substituição à anterior
api_key = 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

# Endpoint da API
# Não altere a menos que a URL da API mude oficialmente
endpoint = https://openrouter.ai/api/v1

# Modelo padrão a ser utilizado
default_model = deepseek/deepseek-r1-0528:free

# Lista de modelos alternativos
models = anthropic/claude-3-opus, google/gemini-pro, meta/llama-3-70b

temperature = 0.7
max_tokens = 2000

... (restante do arquivo permanece inalterado)